{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: sympy in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: filelock in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: fsspec in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: networkx in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/vsetty/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        # Input layer to hidden layer\n",
    "        self.hidden = nn.Linear(2, 5)  # Assuming input features are of size 2, and hidden layer has 5 nodes\n",
    "        self.hidden2 = nn.Linear(5, 8)\n",
    "        # Hidden layer to output layer\n",
    "        self.output = nn.Linear(8, 1)  # Output layer for binary classification (1 node)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass: compute the output of the network\n",
    "        a1 = F.relu(self.hidden(x))\n",
    "        a2 = F.relu(self.hidden2(a1))\n",
    "        x = torch.sigmoid(self.output(a2))  # Activation function for output layer for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNet(\n",
      "  (hidden): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (hidden2): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[ 0.1498, -0.2089]])\n",
      "Output of the network: tensor([[0.5534]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the network\n",
    "my_net = SimpleNeuralNet()\n",
    "print(my_net)\n",
    "\n",
    "# Dummy input for testing the network\n",
    "dummy_input = torch.randn(1, 2)  # Batch size of 1, input features of size 2\n",
    "print(dummy_input)\n",
    "output = my_net(dummy_input)\n",
    "print(\"Output of the network:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6921742558479309\n",
      "Epoch 10, Loss: 0.5985599160194397\n",
      "Epoch 20, Loss: 0.4870801866054535\n",
      "Epoch 30, Loss: 0.4468354880809784\n",
      "Epoch 40, Loss: 0.4401010274887085\n",
      "Epoch 50, Loss: 0.4399012327194214\n",
      "Epoch 60, Loss: 0.43844524025917053\n",
      "Epoch 70, Loss: 0.4376726746559143\n",
      "Epoch 80, Loss: 0.43708038330078125\n",
      "Epoch 90, Loss: 0.4363258481025696\n",
      "Final Loss: 0.43558114767074585\n"
     ]
    }
   ],
   "source": [
    "# Synthetic non-linear dataset\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=600, noise=0.5, random_state=42)  # Create non-linear data\n",
    "inputs = torch.tensor(X, dtype=torch.float)  # Convert to tensors\n",
    "labels = torch.tensor(y, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "# Splitting dataset into train and test\n",
    "train_inputs, test_inputs = inputs[:540], inputs[540:]\n",
    "train_labels, test_labels = labels[:540], labels[540:]\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(my_net.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
    "\n",
    "# Training loop (for demonstration, let's say 100 epochs)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    predicted_labels = my_net(inputs)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(predicted_labels, labels)\n",
    "    if epoch % 10 == 0:  # Print every 10 epochs\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Print final loss\n",
    "print(f'Final Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: \n",
    "a. Implement the predict function by running the prediction through neural network and return the predicted labels.\n",
    "b. Compute the accuracy for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # Apply the network to the input\n",
    "    predicted = my_net(x)\n",
    "    # Convert the output to binary\n",
    "    predicted = (predicted > 0.5).float()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    # Compare the predicted labels to true labels\n",
    "    return (y_pred == y_true).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = predict(test_inputs)\n",
    "test_accuracy = accuracy(test_pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "a. Change the network to use ReLU activation function, and train again\n",
    "b. Change the optimization algorithm to Adam and train again\n",
    "c. Add an additional hidden layer and train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, activation_function, input_size=2, hidden_sizes=[5, 8], output_size=1):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # Add input layer\n",
    "        if num_hidden_layers > 0:\n",
    "            self.layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "\n",
    "        # Add hidden layers\n",
    "        for i in range(1, num_hidden_layers):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
    "\n",
    "        # Add output layer\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass: compute the output of the network\n",
    "        for i in range(len(self.layers) - 1):  # Loop over all layers except the output layer\n",
    "            x = self.layers[i](x)\n",
    "            if self.activation_function == 'relu':\n",
    "                x = F.relu(x)\n",
    "            elif self.activation_function == 'sigmoid':\n",
    "                x = torch.sigmoid(x)\n",
    "            elif self.activation_function == 'tanh':\n",
    "                x = torch.tanh(x)\n",
    "            # Add more activation functions as needed\n",
    "\n",
    "        # Activation function for output layer for binary classification\n",
    "        x = torch.sigmoid(self.layers[-1](x)) \n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Apply the network to the input\n",
    "        predicted = self(x)\n",
    "        # Convert the output to binary\n",
    "        predicted = (predicted > 0.5).float()\n",
    "        return predicted\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = SimpleNeuralNet(num_hidden_layers=2, activation_function='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6806690692901611\n",
      "Epoch 10, Loss: 0.6806690692901611\n",
      "Epoch 20, Loss: 0.6806690692901611\n",
      "Epoch 30, Loss: 0.6806690692901611\n",
      "Epoch 40, Loss: 0.6806690692901611\n",
      "Epoch 50, Loss: 0.6806690692901611\n",
      "Epoch 60, Loss: 0.6806690692901611\n",
      "Epoch 70, Loss: 0.6806690692901611\n",
      "Epoch 80, Loss: 0.6806690692901611\n",
      "Epoch 90, Loss: 0.6806690692901611\n",
      "Final Loss: 0.6806690692901611\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    predicted_labels = nn_model(inputs)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(predicted_labels, labels)\n",
    "    if epoch % 10 == 0:  # Print every 10 epochs\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Print final loss\n",
    "print(f'Final Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = nn_model.predict(test_inputs)\n",
    "test_accuracy = accuracy(test_pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5333)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
