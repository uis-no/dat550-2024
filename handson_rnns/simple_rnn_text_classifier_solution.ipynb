{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Use LSTM for text classification. Sentiment classification using sample movie review dataset. \n",
    "- Represent words using 1-hot encoding\n",
    "- Encode words as 1-hot encoded vectors and feed them to an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, rnn_type='rnn'):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn_type = rnn_type\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        elif rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN type\")\n",
    "        # Output layer for binary classification (1 node)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        if self.rnn_type == \"lstm\":\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "            out, _ = self.rnn(x, (h0, c0))\n",
    "        else:\n",
    "            out, _ = self.rnn(x, h0)\n",
    "\n",
    "        # Extract the last hidden state output\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Pass the last hidden state output to fully connected layer\n",
    "        out = self.fc(out)\n",
    "        # Apply sigmoid function to convert to a probability\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Example usage:\n",
    "input_size = 10   # Number of input features\n",
    "hidden_size = 10  # Number of features in the hidden state\n",
    "num_layers = 1    # Number of stacked RNN layers\n",
    "\n",
    "# Create the RNN model instance\n",
    "model = SimpleRNN(input_size, hidden_size, num_layers, rnn_type='lstm')\n",
    "\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Example sentiment analysis data\n",
    "texts = [\n",
    "    \"I loved the movie\",  # Positive sentiment\n",
    "    \"I hated the movie\",  # Negative sentiment\n",
    "    \"A great movie. Fantastic characters.\",  # Positive sentiment\n",
    "    \"Poor plot, boring scenes.\",  # Negative sentiment\n",
    "]\n",
    "Y = torch.tensor([1, 0, 1, 0], dtype=torch.float32)\n",
    "\n",
    "# Create vocabulary\n",
    "token_counter = Counter(token for text in texts for token in text.split())\n",
    "vocab = {token: i for i, token in enumerate(token_counter)}\n",
    "VOCAB_SIZE = len(vocab)\n",
    "# One-Hot Encode Texts\n",
    "def one_hot_encode(text, vocab):\n",
    "    encoding = np.zeros((len(text.split()), len(vocab)), dtype=int)\n",
    "    for i, token in enumerate(text.split()):\n",
    "        if token in vocab:  # Check if token is in vocab\n",
    "            encoding[i, vocab[token]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "encoded_texts = [one_hot_encode(text, vocab) for text in texts]\n",
    "max_length = max(len(text) for text in encoded_texts)\n",
    "\n",
    "# Pad the sequences and convert X to a tensor\n",
    "padded_texts = [np.pad(text, ((0, max_length - len(text)), (0, 0)), 'constant') for text in encoded_texts]\n",
    "X_padded = torch.tensor(padded_texts, dtype=torch.float32)  # Shape: [batch_size, max_length, VOCAB_SIZE]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = VOCAB_SIZE\n",
    "hidden_size = 50  \n",
    "num_layers = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "model = SimpleRNN(input_size, hidden_size, num_layers, rnn_type='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "def train(train_model, x, y, optimizer_name=\"adam\", model_type = \"RNN\"):\n",
    "    criterion = nn.BCELoss()\n",
    "    lr = 0.01\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam(train_model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(train_model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(train_model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer.\")\n",
    "    wandb.init(project='dat550_rnn_text', reinit=True, name=f'run_{model_type}_{optimizer_name}')\n",
    "    # Training loop (for demonstration, let's say 100 epochs)\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        pred = train_model(x)\n",
    "        loss = criterion(pred.squeeze(), y.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(epoch, loss.item())\n",
    "        wandb.log({\"epoch\": epoch, \"loss\": loss})\n",
    "\n",
    "\n",
    "    print(f'Final Loss: {loss.item()}')\n",
    "    wandb.finish()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140015-z6733kfs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/z6733kfs' target=\"_blank\">run_lstm_adam</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/z6733kfs' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/z6733kfs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.1154362173092522e-07\n",
      "1 1.8160166348479834e-07\n",
      "2 1.8146941727081867e-07\n",
      "3 1.5154509469539335e-07\n",
      "4 1.5143002940476435e-07\n",
      "5 1.2152069928106357e-07\n",
      "6 1.2141916272412345e-07\n",
      "7 9.152162050440893e-08\n",
      "8 9.143045076598355e-08\n",
      "9 9.134417666700756e-08\n",
      "10 9.126316768970355e-08\n",
      "11 6.138522223864129e-08\n",
      "12 6.131274687959376e-08\n",
      "13 6.124383844507975e-08\n",
      "14 6.117872430877469e-08\n",
      "15 6.111746131409745e-08\n",
      "16 3.1257727073352726e-08\n",
      "17 3.1202191053125716e-08\n",
      "18 3.1148818635529096e-08\n",
      "19 3.109779811438784e-08\n",
      "20 3.1049246729253355e-08\n",
      "21 3.100320000726242e-08\n",
      "22 3.095966150112872e-08\n",
      "23 3.091859213100179e-08\n",
      "24 3.0879917289894365e-08\n",
      "25 3.084355526539184e-08\n",
      "26 3.080940658151121e-08\n",
      "27 3.077736110412843e-08\n",
      "28 3.0747312251833137e-08\n",
      "29 3.071915699592864e-08\n",
      "30 3.069277099143619e-08\n",
      "31 3.06680512096591e-08\n",
      "32 3.064490528004171e-08\n",
      "33 3.0623215963032635e-08\n",
      "34 3.0602897993503575e-08\n",
      "35 3.058386610632624e-08\n",
      "36 7.637002696903039e-10\n",
      "37 7.457945927491494e-10\n",
      "38 7.279356561973316e-10\n",
      "39 7.102199939268417e-10\n",
      "40 6.927283191515698e-10\n",
      "41 6.755259684965154e-10\n",
      "42 6.586680645348508e-10\n",
      "43 6.421955744961849e-10\n",
      "44 6.261434148946421e-10\n",
      "45 6.105358441033104e-10\n",
      "46 5.953876835995686e-10\n",
      "47 5.807119785039561e-10\n",
      "48 5.665135582866299e-10\n",
      "49 5.527952540163028e-10\n",
      "50 5.395491831095001e-10\n",
      "51 5.267732361424748e-10\n",
      "52 5.144598080875085e-10\n",
      "53 5.025961313798177e-10\n",
      "54 4.91172935657147e-10\n",
      "55 4.801768982432009e-10\n",
      "56 4.695935862386591e-10\n",
      "57 4.5941006554528485e-10\n",
      "58 4.4961115386321637e-10\n",
      "59 4.401807807141722e-10\n",
      "60 4.3110684466718396e-10\n",
      "61 4.2237466302275095e-10\n",
      "62 4.139677489689575e-10\n",
      "63 4.0587444516404503e-10\n",
      "64 3.980805962644496e-10\n",
      "65 3.905734902165392e-10\n",
      "66 3.833387773877206e-10\n",
      "67 3.763665767930746e-10\n",
      "68 3.696417338883151e-10\n",
      "69 3.6315683793475273e-10\n",
      "70 3.5689803890015526e-10\n",
      "71 3.5085617744456954e-10\n",
      "72 3.450211782940471e-10\n",
      "73 3.393842151755422e-10\n",
      "74 3.3393549037086245e-10\n",
      "75 3.286663996515671e-10\n",
      "76 3.2356808898903466e-10\n",
      "77 3.1863511829044455e-10\n",
      "78 3.1385755105972635e-10\n",
      "79 3.09230696604601e-10\n",
      "80 3.047463670302619e-10\n",
      "81 3.003981507987419e-10\n",
      "82 2.961808853729764e-10\n",
      "83 2.920885477930568e-10\n",
      "84 2.881159755219187e-10\n",
      "85 2.8425811704479997e-10\n",
      "86 2.8050967104675806e-10\n",
      "87 2.768666684804799e-10\n",
      "88 2.7332358598641804e-10\n",
      "89 2.698768153397424e-10\n",
      "90 2.665233311827109e-10\n",
      "91 2.632581930228639e-10\n",
      "92 2.6007870856936677e-10\n",
      "93 2.5697974304073057e-10\n",
      "94 2.539613241925309e-10\n",
      "95 2.510180674430984e-10\n",
      "96 2.4814725274602267e-10\n",
      "97 2.453457714768348e-10\n",
      "98 2.4261295750171996e-10\n",
      "99 2.399439813505211e-10\n",
      "Final Loss: 2.399439813505211e-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▅▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_adam</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/z6733kfs' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/z6733kfs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140015-z6733kfs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): LSTM(14, 50, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train(model, x=X_padded, y=Y, model_type=\"lstm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM using the SGD, Adam and RMSProp optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140022-x41eg8ng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/x41eg8ng' target=\"_blank\">run_lstm_sgd</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/x41eg8ng' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/x41eg8ng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6960824728012085\n",
      "1 0.6960626840591431\n",
      "2 0.6960430145263672\n",
      "3 0.6960232853889465\n",
      "4 0.6960036754608154\n",
      "5 0.6959840655326843\n",
      "6 0.6959645748138428\n",
      "7 0.6959450244903564\n",
      "8 0.6959255337715149\n",
      "9 0.6959060430526733\n",
      "10 0.6958866715431213\n",
      "11 0.6958673000335693\n",
      "12 0.6958478093147278\n",
      "13 0.6958285570144653\n",
      "14 0.6958092451095581\n",
      "15 0.6957899332046509\n",
      "16 0.6957707405090332\n",
      "17 0.6957516670227051\n",
      "18 0.6957324743270874\n",
      "19 0.6957133412361145\n",
      "20 0.6956942081451416\n",
      "21 0.6956751346588135\n",
      "22 0.6956561803817749\n",
      "23 0.6956372261047363\n",
      "24 0.695618212223053\n",
      "25 0.6955991983413696\n",
      "26 0.695580244064331\n",
      "27 0.695561408996582\n",
      "28 0.695542573928833\n",
      "29 0.695523738861084\n",
      "30 0.6955049633979797\n",
      "31 0.6954861879348755\n",
      "32 0.695467472076416\n",
      "33 0.6954487562179565\n",
      "34 0.6954301595687866\n",
      "35 0.6954114437103271\n",
      "36 0.6953927874565125\n",
      "37 0.6953742504119873\n",
      "38 0.6953556537628174\n",
      "39 0.6953371167182922\n",
      "40 0.6953186392784119\n",
      "41 0.6953001618385315\n",
      "42 0.6952817440032959\n",
      "43 0.6952633261680603\n",
      "44 0.6952449083328247\n",
      "45 0.6952265501022339\n",
      "46 0.6952081322669983\n",
      "47 0.6951898336410522\n",
      "48 0.695171594619751\n",
      "49 0.6951532959938049\n",
      "50 0.6951349973678589\n",
      "51 0.6951168775558472\n",
      "52 0.6950986385345459\n",
      "53 0.6950805187225342\n",
      "54 0.6950623393058777\n",
      "55 0.695044219493866\n",
      "56 0.6950260996818542\n",
      "57 0.6950080394744873\n",
      "58 0.6949900388717651\n",
      "59 0.6949720978736877\n",
      "60 0.6949540972709656\n",
      "61 0.6949360966682434\n",
      "62 0.6949180960655212\n",
      "63 0.6949002146720886\n",
      "64 0.694882333278656\n",
      "65 0.6948645114898682\n",
      "66 0.6948466300964355\n",
      "67 0.6948287487030029\n",
      "68 0.6948109865188599\n",
      "69 0.694793164730072\n",
      "70 0.694775402545929\n",
      "71 0.6947576999664307\n",
      "72 0.6947399973869324\n",
      "73 0.6947222352027893\n",
      "74 0.6947046518325806\n",
      "75 0.6946869492530823\n",
      "76 0.6946693658828735\n",
      "77 0.69465172290802\n",
      "78 0.694634199142456\n",
      "79 0.6946165561676025\n",
      "80 0.6945990324020386\n",
      "81 0.6945815086364746\n",
      "82 0.6945639848709106\n",
      "83 0.6945465803146362\n",
      "84 0.6945290565490723\n",
      "85 0.6945115923881531\n",
      "86 0.6944941878318787\n",
      "87 0.694476842880249\n",
      "88 0.6944593787193298\n",
      "89 0.6944419741630554\n",
      "90 0.6944246888160706\n",
      "91 0.6944073438644409\n",
      "92 0.694390058517456\n",
      "93 0.6943727135658264\n",
      "94 0.6943555474281311\n",
      "95 0.6943382024765015\n",
      "96 0.6943209767341614\n",
      "97 0.6943038105964661\n",
      "98 0.694286584854126\n",
      "99 0.6942694783210754\n",
      "Final Loss: 0.6942694783210754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.69427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_sgd</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/x41eg8ng' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/x41eg8ng</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140022-x41eg8ng/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140034-396y5jwx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/396y5jwx' target=\"_blank\">run_lstm_adam</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/396y5jwx' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/396y5jwx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6942522525787354\n",
      "1 0.6838241815567017\n",
      "2 0.67153400182724\n",
      "3 0.6529476642608643\n",
      "4 0.6238479614257812\n",
      "5 0.5792327523231506\n",
      "6 0.5127093195915222\n",
      "7 0.4224400222301483\n",
      "8 0.3173147439956665\n",
      "9 0.20733854174613953\n",
      "10 0.11310096085071564\n",
      "11 0.04737548530101776\n",
      "12 0.01903168298304081\n",
      "13 0.0082006910815835\n",
      "14 0.0042136237025260925\n",
      "15 0.002495621331036091\n",
      "16 0.001624763011932373\n",
      "17 0.0011288704117760062\n",
      "18 0.0008224203484132886\n",
      "19 0.0006213767919689417\n",
      "20 0.0004834167193621397\n",
      "21 0.00038535590283572674\n",
      "22 0.00031367799965664744\n",
      "23 0.00026005582185462117\n",
      "24 0.00021916825789958239\n",
      "25 0.00018744374392554164\n",
      "26 0.00016245830920524895\n",
      "27 0.00014252823893912137\n",
      "28 0.00012645219976548105\n",
      "29 0.0001133006953750737\n",
      "30 0.00010251045023323968\n",
      "31 9.34990675887093e-05\n",
      "32 8.597419946454465e-05\n",
      "33 7.962190284160897e-05\n",
      "34 7.421668851748109e-05\n",
      "35 6.95547932991758e-05\n",
      "36 6.559822213603184e-05\n",
      "37 6.214310269569978e-05\n",
      "38 5.91148818784859e-05\n",
      "39 5.6476830650353804e-05\n",
      "40 5.419855369837023e-05\n",
      "41 5.2165400120429695e-05\n",
      "42 5.035621143179014e-05\n",
      "43 4.875321246800013e-05\n",
      "44 4.731148510472849e-05\n",
      "45 4.60480478068348e-05\n",
      "46 4.48625251010526e-05\n",
      "47 4.383494524518028e-05\n",
      "48 4.289760545361787e-05\n",
      "49 4.2043509893119335e-05\n",
      "50 4.1266550397267565e-05\n",
      "51 4.056147008668631e-05\n",
      "52 3.992360507254489e-05\n",
      "53 3.931911487597972e-05\n",
      "54 3.877422204823233e-05\n",
      "55 3.825598832918331e-05\n",
      "56 3.782122803386301e-05\n",
      "57 3.737812949111685e-05\n",
      "58 3.69840745406691e-05\n",
      "59 3.6607332731364295e-05\n",
      "60 3.624615783337504e-05\n",
      "61 3.592886059777811e-05\n",
      "62 3.562423080438748e-05\n",
      "63 3.5331064282217994e-05\n",
      "64 3.5048258723691106e-05\n",
      "65 3.480463055893779e-05\n",
      "66 3.4539705666247755e-05\n",
      "67 3.431225923122838e-05\n",
      "68 3.409184137126431e-05\n",
      "69 3.384794035810046e-05\n",
      "70 3.366943565197289e-05\n",
      "71 3.3466370950918645e-05\n",
      "72 3.326811201986857e-05\n",
      "73 3.3104046451626346e-05\n",
      "74 3.291414031991735e-05\n",
      "75 3.2727886718930677e-05\n",
      "76 3.257479693274945e-05\n",
      "77 3.239496436435729e-05\n",
      "78 3.224774991394952e-05\n",
      "79 3.207334520993754e-05\n",
      "80 3.196091347490437e-05\n",
      "81 3.1820884032640606e-05\n",
      "82 3.1653104088036343e-05\n",
      "83 3.151698911096901e-05\n",
      "84 3.135285442112945e-05\n",
      "85 3.1249936000676826e-05\n",
      "86 3.111873957095668e-05\n",
      "87 3.095917418249883e-05\n",
      "88 3.083073897869326e-05\n",
      "89 3.070355887757614e-05\n",
      "90 3.057754292967729e-05\n",
      "91 3.0452651117229834e-05\n",
      "92 3.032882887055166e-05\n",
      "93 3.0205985240172595e-05\n",
      "94 3.0084103855188005e-05\n",
      "95 2.9963135602883995e-05\n",
      "96 2.9843020456610247e-05\n",
      "97 2.972375114040915e-05\n",
      "98 2.963509177789092e-05\n",
      "99 2.948758628917858e-05\n",
      "Final Loss: 2.948758628917858e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>3e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_adam</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/396y5jwx' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/396y5jwx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140034-396y5jwx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140042-5imiwty2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/5imiwty2' target=\"_blank\">run_lstm_rmsprop</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/5imiwty2' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/5imiwty2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.9370654374361038e-05\n",
      "1 3.8123111724853516\n",
      "2 5.704899787902832\n",
      "3 1.0666062831878662\n",
      "4 1.337188482284546\n",
      "5 0.33512210845947266\n",
      "6 0.2433239221572876\n",
      "7 0.17142261564731598\n",
      "8 0.097152940928936\n",
      "9 0.050504766404628754\n",
      "10 0.030599597841501236\n",
      "11 0.023140035569667816\n",
      "12 0.018418574705719948\n",
      "13 0.013997294008731842\n",
      "14 0.012892886996269226\n",
      "15 0.012012801133096218\n",
      "16 0.01124551985412836\n",
      "17 0.010521749965846539\n",
      "18 0.009757516905665398\n",
      "19 0.00885146763175726\n",
      "20 0.008013758808374405\n",
      "21 0.007507922127842903\n",
      "22 0.007119504734873772\n",
      "23 0.006766036618500948\n",
      "24 0.006415664218366146\n",
      "25 0.0060475110076367855\n",
      "26 0.005667844321578741\n",
      "27 0.005323977209627628\n",
      "28 0.005040121730417013\n",
      "29 0.004789636004716158\n",
      "30 0.004507836885750294\n",
      "31 0.0041071041487157345\n",
      "32 0.0039116558618843555\n",
      "33 0.0037967958487570286\n",
      "34 0.0036948174238204956\n",
      "35 0.0036010455805808306\n",
      "36 0.003513556206598878\n",
      "37 0.003431259887292981\n",
      "38 0.0033535375259816647\n",
      "39 0.003279798896983266\n",
      "40 0.003209623508155346\n",
      "41 0.003142738714814186\n",
      "42 0.003078746609389782\n",
      "43 0.0030174939893186092\n",
      "44 0.0029586940072476864\n",
      "45 0.002902147825807333\n",
      "46 0.0028477103915065527\n",
      "47 0.0027951595839112997\n",
      "48 0.002744433004409075\n",
      "49 0.002695340197533369\n",
      "50 0.0026477465871721506\n",
      "51 0.002601562300696969\n",
      "52 0.0025567319244146347\n",
      "53 0.002513060811907053\n",
      "54 0.0024704982060939074\n",
      "55 0.0024289258290082216\n",
      "56 0.002388252876698971\n",
      "57 0.0023483773693442345\n",
      "58 0.002309267409145832\n",
      "59 0.002270803088322282\n",
      "60 0.0022329320199787617\n",
      "61 0.002195582026615739\n",
      "62 0.002158760791644454\n",
      "63 0.002122462959960103\n",
      "64 0.0020865891128778458\n",
      "65 0.0020510905887931585\n",
      "66 0.0020158826373517513\n",
      "67 0.0019807806238532066\n",
      "68 0.0019456013105809689\n",
      "69 0.0019099419005215168\n",
      "70 0.0018736144993454218\n",
      "71 0.0018365253927186131\n",
      "72 0.0017991700442507863\n",
      "73 0.0017624166794121265\n",
      "74 0.0017272341065108776\n",
      "75 0.0016941885696724057\n",
      "76 0.0016632165061309934\n",
      "77 0.0016339088324457407\n",
      "78 0.0016058984911069274\n",
      "79 0.0015788576565682888\n",
      "80 0.0015526209026575089\n",
      "81 0.001527169719338417\n",
      "82 0.0015025337925180793\n",
      "83 0.0014789375709369779\n",
      "84 0.0014564474113285542\n",
      "85 0.001434985431842506\n",
      "86 0.0014145552413538098\n",
      "87 0.0013949776766821742\n",
      "88 0.001376153202727437\n",
      "89 0.001358017441816628\n",
      "90 0.0013404041528701782\n",
      "91 0.0013233465142548084\n",
      "92 0.0013067405670881271\n",
      "93 0.001290608081035316\n",
      "94 0.0012748793233186007\n",
      "95 0.001259548356756568\n",
      "96 0.0012445474276319146\n",
      "97 0.00122992938850075\n",
      "98 0.0012156759621575475\n",
      "99 0.0012017195113003254\n",
      "Final Loss: 0.0012017195113003254\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.0012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_rmsprop</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/5imiwty2' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/5imiwty2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140042-5imiwty2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): LSTM(14, 50, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lstm = SimpleRNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, rnn_type=\"lstm\")\n",
    "train(simple_lstm, x=X_padded, y=Y, model_type=\"lstm\", optimizer_name=\"sgd\")\n",
    "train(simple_lstm, x=X_padded, y=Y, model_type=\"lstm\", optimizer_name=\"adam\")\n",
    "train(simple_lstm, x=X_padded, y=Y, model_type=\"lstm\", optimizer_name=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Implement a SimpleLSTMAttention which adds an attention layer on top of LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMWithAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # Attention layer\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))  # shape of lstm_out: [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out).squeeze(-1), dim=1)  # shape: [batch_size, seq_len]\n",
    "        # Multiply weights by LSTM outputs (element-wise)\n",
    "        context_vector = torch.einsum('ij,ijk->ik', attention_weights, lstm_out)  # shape: [batch_size, hidden_size]\n",
    "\n",
    "        # Pass the context vector through the linear layer\n",
    "        out = self.fc(context_vector)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Log the learning curve to wandb and repeat all experiments with LSTMWithAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140058-sq0covgs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sq0covgs' target=\"_blank\">run_lstm_attn_sgd</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sq0covgs' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sq0covgs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6953690052032471\n",
      "1 0.6953569650650024\n",
      "2 0.6953449249267578\n",
      "3 0.6953328847885132\n",
      "4 0.6953209638595581\n",
      "5 0.6953089237213135\n",
      "6 0.6952969431877136\n",
      "7 0.6952850818634033\n",
      "8 0.6952731609344482\n",
      "9 0.6952612996101379\n",
      "10 0.6952494382858276\n",
      "11 0.6952375173568726\n",
      "12 0.6952257752418518\n",
      "13 0.695214033126831\n",
      "14 0.6952022314071655\n",
      "15 0.6951904892921448\n",
      "16 0.695178747177124\n",
      "17 0.6951671242713928\n",
      "18 0.6951553821563721\n",
      "19 0.6951436996459961\n",
      "20 0.6951320767402649\n",
      "21 0.6951204538345337\n",
      "22 0.6951088905334473\n",
      "23 0.6950972676277161\n",
      "24 0.6950857639312744\n",
      "25 0.6950742602348328\n",
      "26 0.6950627565383911\n",
      "27 0.6950512528419495\n",
      "28 0.6950397491455078\n",
      "29 0.6950283050537109\n",
      "30 0.6950169205665588\n",
      "31 0.695005476474762\n",
      "32 0.6949940919876099\n",
      "33 0.6949827075004578\n",
      "34 0.6949713826179504\n",
      "35 0.6949601173400879\n",
      "36 0.6949487328529358\n",
      "37 0.6949374675750732\n",
      "38 0.6949261426925659\n",
      "39 0.6949149966239929\n",
      "40 0.6949037909507751\n",
      "41 0.6948925256729126\n",
      "42 0.6948813199996948\n",
      "43 0.694870114326477\n",
      "44 0.6948590278625488\n",
      "45 0.6948478817939758\n",
      "46 0.6948367953300476\n",
      "47 0.6948256492614746\n",
      "48 0.6948146820068359\n",
      "49 0.6948034763336182\n",
      "50 0.6947925090789795\n",
      "51 0.6947815418243408\n",
      "52 0.6947704553604126\n",
      "53 0.6947594881057739\n",
      "54 0.6947485208511353\n",
      "55 0.6947375535964966\n",
      "56 0.6947267055511475\n",
      "57 0.6947156190872192\n",
      "58 0.6947047710418701\n",
      "59 0.6946938037872314\n",
      "60 0.6946830749511719\n",
      "61 0.694672167301178\n",
      "62 0.6946613788604736\n",
      "63 0.6946505904197693\n",
      "64 0.6946396827697754\n",
      "65 0.6946290135383606\n",
      "66 0.6946181654930115\n",
      "67 0.6946074366569519\n",
      "68 0.6945966482162476\n",
      "69 0.6945860385894775\n",
      "70 0.6945752501487732\n",
      "71 0.6945645809173584\n",
      "72 0.6945538520812988\n",
      "73 0.6945432424545288\n",
      "74 0.694532573223114\n",
      "75 0.694521963596344\n",
      "76 0.694511353969574\n",
      "77 0.6945008039474487\n",
      "78 0.6944901943206787\n",
      "79 0.6944796442985535\n",
      "80 0.6944690346717834\n",
      "81 0.6944584846496582\n",
      "82 0.6944479942321777\n",
      "83 0.6944375038146973\n",
      "84 0.6944270133972168\n",
      "85 0.6944165229797363\n",
      "86 0.6944060921669006\n",
      "87 0.6943956613540649\n",
      "88 0.6943851709365845\n",
      "89 0.6943747997283936\n",
      "90 0.6943643093109131\n",
      "91 0.6943539977073669\n",
      "92 0.6943435668945312\n",
      "93 0.6943332552909851\n",
      "94 0.694322943687439\n",
      "95 0.6943125128746033\n",
      "96 0.6943021416664124\n",
      "97 0.694291889667511\n",
      "98 0.6942815780639648\n",
      "99 0.6942712664604187\n",
      "Final Loss: 0.6942712664604187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.69427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_attn_sgd</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sq0covgs' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sq0covgs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140058-sq0covgs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140105-sr8mh1y4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sr8mh1y4' target=\"_blank\">run_lstm_attn_adam</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sr8mh1y4' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sr8mh1y4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.37337843822516e-10\n",
      "1 2.3466201204414006e-10\n",
      "2 2.3203186594322744e-10\n",
      "3 2.2944735000862693e-10\n",
      "4 2.2690724299501142e-10\n",
      "5 2.244127800254958e-10\n",
      "6 2.2196013083064514e-10\n",
      "7 2.1955147422314525e-10\n",
      "8 2.1718467302367372e-10\n",
      "9 2.1486062928843808e-10\n",
      "10 2.1257763604953794e-10\n",
      "11 2.1033536024006594e-10\n",
      "12 2.0813301082611702e-10\n",
      "13 2.0597021310742036e-10\n",
      "14 2.038466201392808e-10\n",
      "15 2.0176069148725162e-10\n",
      "16 1.997121218400011e-10\n",
      "17 1.9770053649725838e-10\n",
      "18 1.9572526932520873e-10\n",
      "19 1.9378565419003735e-10\n",
      "20 1.9188062250208304e-10\n",
      "21 1.9001060447276785e-10\n",
      "22 1.8817356006728403e-10\n",
      "23 1.863688231518168e-10\n",
      "24 1.8459722639363463e-10\n",
      "25 1.82857146091564e-10\n",
      "26 1.8114830468984877e-10\n",
      "27 1.7946946706537403e-10\n",
      "28 1.778204528068983e-10\n",
      "29 1.7620034598042622e-10\n",
      "30 1.7460899393029194e-10\n",
      "31 1.7304553623365138e-10\n",
      "32 1.7150950104571905e-10\n",
      "33 1.700000695770143e-10\n",
      "34 1.685164507936321e-10\n",
      "35 1.6705853367326995e-10\n",
      "36 1.6562586024893022e-10\n",
      "37 1.642176811200713e-10\n",
      "38 1.6283326076393934e-10\n",
      "39 1.6147193304671958e-10\n",
      "40 1.6013358694610957e-10\n",
      "41 1.5881723713917495e-10\n",
      "42 1.575234109818524e-10\n",
      "43 1.5625027660615132e-10\n",
      "44 1.5499836136800837e-10\n",
      "45 1.5376613871076472e-10\n",
      "46 1.5255478824638402e-10\n",
      "47 1.5136220055111949e-10\n",
      "48 1.5018897236984685e-10\n",
      "49 1.4903422940193423e-10\n",
      "50 1.4789737490250587e-10\n",
      "51 1.4677845050492522e-10\n",
      "52 1.4567712314228487e-10\n",
      "53 1.445926295362554e-10\n",
      "54 1.4352469213108066e-10\n",
      "55 1.4247281132639955e-10\n",
      "56 1.4143697324442428e-10\n",
      "57 1.4041671991815718e-10\n",
      "58 1.3941126031369322e-10\n",
      "59 1.384211772981203e-10\n",
      "60 1.3744522187053576e-10\n",
      "61 1.3648394914245188e-10\n",
      "62 1.3553586031278542e-10\n",
      "63 1.34602065604561e-10\n",
      "64 1.3368081641651486e-10\n",
      "65 1.3277347277185214e-10\n",
      "66 1.3187831382488469e-10\n",
      "67 1.309957003980955e-10\n",
      "68 1.3012542432466745e-10\n",
      "69 1.2926736070451028e-10\n",
      "70 1.2842034380344813e-10\n",
      "71 1.2758519241096167e-10\n",
      "72 1.2676151794899226e-10\n",
      "73 1.259482101945153e-10\n",
      "74 1.2514608793701143e-10\n",
      "75 1.243545266760293e-10\n",
      "76 1.2357340151147866e-10\n",
      "77 1.2280230998751307e-10\n",
      "78 1.220414047597984e-10\n",
      "79 1.2129006132788334e-10\n",
      "80 1.2054841846964592e-10\n",
      "81 1.1981587944021044e-10\n",
      "82 1.1909254138409153e-10\n",
      "83 1.183785569569551e-10\n",
      "84 1.176733294139254e-10\n",
      "85 1.1697676161048776e-10\n",
      "86 1.1628852741862872e-10\n",
      "87 1.1560899459972518e-10\n",
      "88 1.1493735824208429e-10\n",
      "89 1.1427399998487076e-10\n",
      "90 1.1361836471657227e-10\n",
      "91 1.1297014018696316e-10\n",
      "92 1.1233054764137052e-10\n",
      "93 1.1169778296737931e-10\n",
      "94 1.1107217229300304e-10\n",
      "95 1.1045406950183079e-10\n",
      "96 1.0984319009921251e-10\n",
      "97 1.0923943000173963e-10\n",
      "98 1.0864189409209857e-10\n",
      "99 1.0805132483193702e-10\n",
      "Final Loss: 1.0805132483193702e-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_attn_adam</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sr8mh1y4' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/sr8mh1y4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140105-sr8mh1y4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnn_text/wandb/run-20240319_140112-ua212ktf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/ua212ktf' target=\"_blank\">run_lstm_attn_rmsprop</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/ua212ktf' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/ua212ktf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0746765977120987e-10\n",
      "1 1.0691365154302801e-10\n",
      "2 1.0636534014674126e-10\n",
      "3 1.0582307252704481e-10\n",
      "4 1.0528617561122999e-10\n",
      "5 1.0475499634399199e-10\n",
      "6 1.0422949309196738e-10\n",
      "7 1.0370898584355359e-10\n",
      "8 1.0319402971026292e-10\n",
      "9 1.0268418754177944e-10\n",
      "10 1.0217938301027019e-10\n",
      "11 1.0167979652697667e-10\n",
      "12 1.0118494930821953e-10\n",
      "13 1.0069520217648176e-10\n",
      "14 1.0021012492034131e-10\n",
      "15 9.972966202864697e-11\n",
      "16 9.925397309595851e-11\n",
      "17 9.878299567223081e-11\n",
      "18 9.831668118520653e-11\n",
      "19 9.785445370669166e-11\n",
      "20 9.739679895925946e-11\n",
      "21 9.69433144870635e-11\n",
      "22 9.64943541736929e-11\n",
      "23 9.604909922966698e-11\n",
      "24 9.560846558898106e-11\n",
      "25 9.51716622177301e-11\n",
      "26 9.473902218282149e-11\n",
      "27 9.43103373174381e-11\n",
      "28 9.38855521104287e-11\n",
      "29 9.34648261563531e-11\n",
      "30 9.304756964922944e-11\n",
      "31 9.263430994499444e-11\n",
      "32 9.222463764890776e-11\n",
      "33 9.181871235552919e-11\n",
      "34 9.14161316090123e-11\n",
      "35 9.101722847626448e-11\n",
      "36 9.062196826281621e-11\n",
      "37 9.022980279604909e-11\n",
      "38 8.984139820977788e-11\n",
      "39 8.945635898705007e-11\n",
      "40 8.907483778353154e-11\n",
      "41 8.869613377093799e-11\n",
      "42 8.832088532750859e-11\n",
      "43 8.794874550854814e-11\n",
      "44 8.757983921414692e-11\n",
      "45 8.72141456276232e-11\n",
      "46 8.685130392649398e-11\n",
      "47 8.649177901665084e-11\n",
      "48 8.613506435883878e-11\n",
      "49 8.578113219748218e-11\n",
      "50 8.54304335606848e-11\n",
      "51 8.508264232043317e-11\n",
      "52 8.473755724880405e-11\n",
      "53 8.439531018478164e-11\n",
      "54 8.405589418947201e-11\n",
      "55 8.371912885163368e-11\n",
      "56 8.338513213246301e-11\n",
      "57 8.305390403196e-11\n",
      "58 8.272493107197576e-11\n",
      "59 8.239915694208122e-11\n",
      "60 8.207543672478224e-11\n",
      "61 8.175470023186193e-11\n",
      "62 8.143631602397505e-11\n",
      "63 8.112024940665208e-11\n",
      "64 8.080679875233088e-11\n",
      "65 8.049593630543583e-11\n",
      "66 8.01870375655156e-11\n",
      "67 7.988115724444356e-11\n",
      "68 7.9577192058089e-11\n",
      "69 7.927559303455567e-11\n",
      "70 7.897634629605577e-11\n",
      "71 7.86792853091356e-11\n",
      "72 7.838454191277933e-11\n",
      "73 7.809208141251744e-11\n",
      "74 7.780160543591208e-11\n",
      "75 7.751353725549137e-11\n",
      "76 7.722757155992355e-11\n",
      "77 7.69436875325269e-11\n",
      "78 7.66618712955136e-11\n",
      "79 7.638224774897395e-11\n",
      "80 7.610467117613595e-11\n",
      "81 7.582881544898612e-11\n",
      "82 7.555526343461239e-11\n",
      "83 7.528341144924511e-11\n",
      "84 7.50138215432905e-11\n",
      "85 7.474620228320461e-11\n",
      "86 7.448010957977758e-11\n",
      "87 7.421623038350589e-11\n",
      "88 7.395427326084558e-11\n",
      "89 7.369393983935879e-11\n",
      "90 7.343566033046756e-11\n",
      "91 7.31791155450523e-11\n",
      "92 7.292443038320329e-11\n",
      "93 7.267146606704245e-11\n",
      "94 7.242022259656977e-11\n",
      "95 7.217065833842184e-11\n",
      "96 7.192305084835482e-11\n",
      "97 7.167698379273446e-11\n",
      "98 7.143258207165104e-11\n",
      "99 7.119008160749729e-11\n",
      "Final Loss: 7.119008160749729e-11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_lstm_attn_rmsprop</strong> at: <a href='https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/ua212ktf' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn_text/runs/ua212ktf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240319_140112-ua212ktf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): LSTM(14, 50, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lstm_attn = LSTMWithAttention(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "train(simple_lstm_attn, x=X_padded, y=Y, model_type=\"lstm_attn\", optimizer_name=\"sgd\")\n",
    "train(model, x=X_padded, y=Y, model_type=\"lstm_attn\", optimizer_name=\"adam\")\n",
    "train(model, x=X_padded, y=Y, model_type=\"lstm_attn\", optimizer_name=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vsetty/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/Users/vsetty/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinays\u001b[0m (\u001b[33mfactiverse-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/vsetty/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Register an account in https://wandb.ai/ and get your API key from https://wandb.ai/authorize\n",
    "# wandb.login(key=\"add your key here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vsetty/repos/dat550/2024/handson_rnns/wandb/run-20240314_155135-o9q93ukf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/factiverse-ai/dat550_rnn/runs/o9q93ukf' target=\"_blank\">rhubarb-meringue-1</a></strong> to <a href='https://wandb.ai/factiverse-ai/dat550_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/factiverse-ai/dat550_rnn' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/factiverse-ai/dat550_rnn/runs/o9q93ukf' target=\"_blank\">https://wandb.ai/factiverse-ai/dat550_rnn/runs/o9q93ukf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/factiverse-ai/dat550_rnn/runs/o9q93ukf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x3389a2250>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"dat550_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
